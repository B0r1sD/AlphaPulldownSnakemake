import sys
from sys import exit
from os.path import abspath, join
from source.input_parser import InputParser

configfile: "config/config.yaml"
config["input_file"] = abspath(config["input_file"])
config["output_directory"] = abspath(config["output_directory"])

dataset = InputParser.from_file(filepath = config["input_file"], file_format = "alphaabriss")


rule all:
    input:
        expand(join(config["output_directory"], "features", "{uniprot_id}.pkl"),
            uniprot_id = dataset.unique_sequences
        ),
        expand(join(
            config["output_directory"], "predictions",
            "{fold}", "completed_fold.txt"
            ),
            fold = dataset.fold_specifications
        ),

rule download_uniprot:
    output:
        join(config["output_directory"], "data", "{uniprot_id}.fasta"),
    resources:
        avg_mem = lambda wildcards, attempt: 600 * attempt,
        mem_mb = lambda wildcards, attempt: 800 * attempt,
        walltime = lambda wildcards, attempt: 10 * attempt,
        attempt = lambda wildcards, attempt: attempt,
    shell:"""
        curl -o {output} https://rest.uniprot.org/uniprotkb/{input}.fasta
        """

memscaling_feature = config["feature_creation_threads"] / 8
rule create_features:
    input:
        rules.download_uniprot.output,
    output:
        join(config["output_directory"], "features", "{uniprot_id}.pkl"),
    params:
        data_directory = config["alphafold_data_directory"],
        output_directory = join(config["output_directory"], "features"),
    resources:
        mem_mb = lambda wildcards, attempt: 64000 * attempt * memscaling_feature,
        walltime = lambda wildcards, attempt: 1440 * attempt,
        attempt = lambda wildcards, attempt: attempt,
    threads:
        config["feature_creation_threads"],
    conda:
        "envs/alphapulldown.yaml"
    shell:"""
        create_individual_features.py \
            --fasta_paths={input} \
            --data_dir={params.data_directory} \
            --output_dir={params.output_directory} \
            --save_msa_files=False \
            --use_precomputed_msas=False \
            --max_template_date=2050-01-01 \
            --skip_existing=False
        """

memscaling_inference = config["feature_creation_threads"] / 8
rule alphafold_inference:
    input:
        lambda wildcards : [join(
            config["output_directory"], "features", f"{feature}.pkl")
            for feature in dataset.sequences_by_fold[wildcards.fold]],
    output:
        join(
            config["output_directory"],
            "predictions", "{fold}", "completed_fold.txt"
        ),
    params:
        data_directory = config["alphafold_data_directory"],
        predictions_per_model = config["predictions_per_model"],
        n_recycles = config["number_of_recycles"],
        feature_directory = join(config["output_directory"], "features"),
        output_directory = lambda wildcards: join(
            config["output_directory"], "predictions", "{fold}"
        ),
        requested_fold = lambda  wildcards : wildcards.fold
    resources:
        mem_mb = lambda wildcards, attempt: 128000 * attempt * memscaling_feature,
        walltime = lambda wildcards, attempt: 1440 * attempt,
        attempt = lambda wildcards, attempt: attempt,
        slurm = config.get("alphafold_inference", ""),
    threads:
        config["feature_creation_threads"],
    conda:
        "envs/alphapulldown.yaml"
    shell:"""
        python3 source/alphafold_inference.py \
            --input {params.requested_fold} \
            --output_directory={params.output_directory} \
            --num_cycle={params.n_recycles} \
            --num_predictions_per_model={params.predictions_per_model} \
            --data_dir={params.data_directory} \
            --features_directory={params.feature_directory}
        echo "Completed" > {output}
        """
